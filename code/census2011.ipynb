{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS2006 Advanced Programming Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "For instructions to start the analysis please refer to the README file. \n",
    "We have completed the following requirements: \n",
    "- Quality control and data refinement\n",
    "- Descriptive analysis of the data\n",
    "- Plotting bar charts and pie charts\n",
    "- Using groupby objects and 3D plots on the results of the grouping\n",
    "- using pandas queries and plotting the filtered dataframes\n",
    "- Used ipywidgets to make plots interactive\n",
    "- Analysed an additional data set : https://statistics.gov.scot/resource?uri=http%3A%2F%2Fstatistics.gov.scot%2Fdata%2Fnet-migration \n",
    "- Used virtual environments\n",
    "- Made a map to display our results\n",
    "- Analysed and optimised our performance and drawn conclusions to the analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python - Group Project 2\n",
    "\n",
    "## Data analysis with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with exploring the content of the dataset.\n",
    "\n",
    "A file named \"census2011_refined.csv\" should be included in the data folder of this project. If this file is missing, remove \"_refined\" from the file name below and run the code within the \"Quality Control and Data Refinement\" section of this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/census2011.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "#### Variables\n",
    "\n",
    "Each field in the census is stored as a 'Unique reference ID' which has a corresponding meaning in English.\n",
    "The file <i>variables.py</i> contains dictionaries that store the reference IDs and what they mean.\n",
    "\n",
    "Currently, the dictionaries implemented so far are:\n",
    "- regions\n",
    "- age_groups\n",
    "- hours_worked_per_week\n",
    "- industries\n",
    "- social_grades\n",
    "- occupations\n",
    "- economic_activities\n",
    "\n",
    "Execute the block below to access these dictionaries, these will be required throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "#### Quality Control and Data Refinement\n",
    "The end result of the following block of code has been provided in a file named <b>\"census2011_refined.csv\"</b>, if there is any need to refine the original csv file again, or if this refined file is missing, then please continue reading, otherwise you may skip this section of the report.\n",
    "\n",
    "To begin the automated process, run the cell below to generate a new file from the old csv.\n",
    "\n",
    "This step is <b>highly recommended</b> as it ensures the validity of the provided data. Going through this process should shrink the file size down by at least ~500 KiB, this is likely due to Windows line endings containing one extra character than Unix line endings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cleanup import clean\n",
    "\n",
    "# Takes Dataframe and filename of refined file (used if required).\n",
    "df_refined = clean(df, \"../data/census2011_refined.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are satisfied with the cleanup process, you can replace the original dataframe with the refined version using the block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_refined\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "#### Descriptive Analysis\n",
    "\n",
    "This section of the report displays statistics about the census dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below displays the number of records in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Person ID\"].count() # used PersonID to count as it is a unique identifier of every row in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below displays the type of each variable in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below displays every value that each variable takes and the number of occurences for each value. Used value_counts() as it shows the number of occurences for each unique value instead of unique() which simply displayed all the unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going through every column in the dataframe\n",
    "for column in df:\n",
    "    if(column != \"Person ID\"):\n",
    "        # displaying all unique values and their occurences\n",
    "        print (column)\n",
    "        occ = df[column].value_counts()\n",
    "        print (occ)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "#### Graphs\n",
    "This section of the report displays 2 bar charts and 2 pie charts based on the census data.\\\n",
    "You will have to import from the file <i>queries.py</i>, please run the cell below first, and then run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queries import *\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<i>Graph 1:</i> bar chart for the number of records for each region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the graph below and make it interactive, we decided to use the selectMultiple widgets from the ipywidgets package. The selectMultiple made more intuitive sense over a dropdown in this case as it allowed us to start the graph of showing all the regions in the bar plot. It is more user-friendly. Just press the Ctrl key while selecting to select multiple regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_regions = df.groupby('Region',).Region.count().items()\n",
    "# print_bars(\"Number of Records per Region\", all_regions, regions)\n",
    "\n",
    "\n",
    "xRow = ['South East', 'London', 'North West', 'East of England', 'West Midlands', 'South West', 'Yorkshire and the Humber', 'East Midlands', 'Wales', 'North East']\n",
    "\n",
    "def graphPlot1(regions) :\n",
    "    # print (regions)\n",
    "    g1 = df['Region'].value_counts()\n",
    "    # drops all the regions that are not selected\n",
    "    if (\"North East\" not in regions) : \n",
    "        g1 = g1.drop(['E12000001'])\n",
    "    if (\"North West\" not in regions) :\n",
    "        g1 = g1.drop(['E12000002'])\n",
    "    if (\"Yorkshire and the Humber\" not in regions) :\n",
    "        g1 = g1.drop(['E12000003'])\n",
    "    if (\"East Midlands\" not in regions) :\n",
    "        g1 = g1.drop(['E12000004'])\n",
    "    if (\"West Midlands\" not in regions) : \n",
    "        g1 = g1.drop(['E12000005']) \n",
    "    if (\"East of England\" not in regions) :\n",
    "        g1 = g1.drop(['E12000006'])\n",
    "    if (\"London\" not in regions) : \n",
    "        g1 = g1.drop(['E12000007']) \n",
    "    if (\"South East\" not in regions) :\n",
    "        g1 = g1.drop(['E12000008'])\n",
    "    if (\"South West\" not in regions) :\n",
    "        g1 = g1.drop(['E12000009'])\n",
    "    if (\"Wales\" not in regions) :\n",
    "        g1 = g1.drop(['W92000004'])\n",
    "   \n",
    "    g1.plot.bar()\n",
    "    plt.ylabel('Records')\n",
    "    label_nums = [x for x in range(0,len(regions))]\n",
    "    plt.xticks(label_nums, regions)\n",
    "    plt.title('Num of Records per Region')\n",
    "    plt.show()\n",
    "\n",
    "# widget definition for selecting multiple regions\n",
    "selectMultiple = widgets.SelectMultiple(\n",
    "                            options  = xRow,\n",
    "                            value =xRow,\n",
    "                            description = \"Region: \",\n",
    "                            disabled = False\n",
    "                            )\n",
    "# interaction defined between graph and regions in a list\n",
    "widgets.interact(graphPlot1, regions =selectMultiple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph 1 shows that the South East of England has the most records in the census at over 80000 entries, suggesting that it is England's most populous region. Conversely, the North East of England has the least amount of records at just under 30000 entries, suggesting that it is the least populous region in England."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<i>Graph 2:</i> bar chart for the number of records for each occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_occupations = df.groupby('Occupation').Occupation.count().items()\n",
    "print_bars(\"Number of Records per Occupation\", all_occupations, occupations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<i>Graph 3:</i> pie chart for the distribution of the sample by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ages = get_condition_by_column(df, df[\"Age\"] <= 8, \"Age\")\n",
    "print_pie(\"Distribution of Age\", all_ages, age_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Graph 4:</i> pie chart for the distribution of the sample by the economic activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_econ_activity = get_condition_by_column(df, df[\"Economic Activity\"] <= 9, \"Economic Activity\")\n",
    "print_pie(\"Distribution of Economic Activity\", all_econ_activity, economic_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the basic graphs: graph 1 and 2 show bar charts on records per region and records per occupation. The two pie charts show the distrubution of the sample by age and show the distrubution of the sample by economic activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "#### Queries\n",
    "\n",
    "This section analyses:\n",
    "<ol>\n",
    "    <li>The number of economically active people (see “Economic activity”) by region.</li>\n",
    "    <li>The number of economically active people (see “Economic activity”) by age.</li>\n",
    "    <li>Whether there are any discrepancies between the student status given as a yes/no answer to the question “Student (Schoolchild or full-time student)” and answers on the question on “Economic activity”.</li>\n",
    "    <li>The number of working hours per week for students (codes 4 and 6 in “Economic activity”).</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pie(\"Distribution of Age\", [(k,str(v)) for (k,v) in df.groupby(\"Age\").Occupation.count().items()], age_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell produces a pie chart of the Number of Economically Active people by Region.\n",
    "\n",
    "economically_active = (df[\"Economic Activity\"] < 5) & (df[\"Economic Activity\"] != -9)\n",
    "\n",
    "economically_active_by_region = get_condition_by_column(df, economically_active, \"Region\");\n",
    "\n",
    "print_pie(\"Number of economically active people by region.\", economically_active_by_region, regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell produces a pie chart of the Number of Economically Active people by Age.\n",
    "\n",
    "economically_active_by_age = get_condition_by_column(df, economically_active, \"Age\");\n",
    "\n",
    "print_pie(\"Number of economically active people by age.\", economically_active_by_age, age_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell displays whether or not there are any students who gave contradictory answers for \"Economic Activity.\"\n",
    "\n",
    "students_economically = (df[\"Economic Activity\"] == 4) | (df[\"Economic Activity\"] == 6) | (df[\"Economic Activity\"] == -9)\n",
    "contradictory_students = (df[\"Student\"] == 1) & ~students_economically\n",
    "\n",
    "contradictions = fulfill(df, contradictory_students)\n",
    "print(\"\")\n",
    "print(\"There are\", str(len(contradictions.index)), 'cases of discrepencies where students have not declared that they are students under \"Economic Activity\".' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell displays a pie chart of the Hours Worked Per Week by students.\n",
    "\n",
    "students_economically = (df[\"Economic Activity\"] == 4) | (df[\"Economic Activity\"] == 6)\n",
    "\n",
    "students_work_per_week = get_condition_by_column(df, students_economically, \"Hours worked per week\")\n",
    "\n",
    "print_pie(\"Hours worked per week by students.\", students_work_per_week, hours_worked_per_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using groupby objects\n",
    "\n",
    "Run the cell below and the following cells to generate the following tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot3d import flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Records by Region and Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_industry_records = df.groupby(['Region', 'Industry']).Region.count()\n",
    "region_industry_df = flatten(region_industry_records, \"Region\", \"Industry\", \"Records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_industry_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Records by Occupation and Social Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_social_grade_records = df.groupby(['Occupation', 'Approximated Social Grade']).Occupation.count()\n",
    "occupation_social_grade_df = flatten(occupation_social_grade_records, \"Occupation\", \"Approximated Social Grade\", \"Records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_social_grade_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D Plots\n",
    "\n",
    "To display the 3D plots, execute the following cell to import the necessary code and then run the cells below.\n",
    "These 3D Plots will use the data from the groupby objects generated in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot3d import generate_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of Records by Region and Industry\n",
    "\n",
    "generate_plot(\"Number of Records by Region and Industry\", region_industry_df, \"Region\", \"Industry\", \"Records\", regions, industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Records by Region and Industry\n",
    "\n",
    "generate_plot(\"Number of Records by Occupation and Social Grade\", occupation_social_grade_df, \"Occupation\", \"Approximated Social Grade\", \"Records\", occupations, social_grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maps\n",
    "\n",
    "To display a circle at each region's geographic center with the diameter corresponding to the number of records in that region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = generate_map(df, list(regions.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the majority of census submissions were from the Southeast of England."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "#### Analysing Performance\n",
    "This section of the report analyses the performance of the functions used for analysis. The times stated in this section will be approximate (indicated by ~n seconds), this is because the timings taken is dependent on the performance of the machine.\n",
    "\n",
    "The first section measures the time taken for each given function to execute. The threshold is set to a very generous 2 seconds, which is chosen arbitrarily as there is no strict threshold for how long a function should take to execute; this section checks which function in particular takes longer than other functions to execute.\n",
    "\n",
    "To run the code cell below, simply execute the first 3 cell blocks of this notebook, if you have not already done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profiler import *\n",
    "\n",
    "# Prerequisites for test functions\n",
    "all_regions = df.groupby('Region',).Region.count().items()\n",
    "economically_active = (df[\"Economic Activity\"] < 5) & (df[\"Economic Activity\"] != -9)\n",
    "economically_active_by_region = get_condition_by_column(df, economically_active, \"Region\")\n",
    "region_industry_records = df.groupby(['Region', 'Industry']).Region.count()\n",
    "region_industry_df = flatten(region_industry_records, \"Region\", \"Industry\", \"Records\")\n",
    "\n",
    "test_functions = [(\"print_bars\" , lambda : print_bars(\"Number of Records per Region\", all_regions, regions)),\n",
    "                  (\"print_pie\", lambda : print_pie(\"Number of economically active people by region.\", economically_active_by_region, regions)),\n",
    "                  (\"get_condition_by_column\", lambda : get_condition_by_column(df, economically_active, \"Region\")),\n",
    "                  (\"flatten\", lambda : flatten(region_industry_records, \"Region\", \"Industry\", \"Records\")),\n",
    "                  (\"generate_plot\", lambda : generate_plot(\"Number of Records by Region and Industry\", region_industry_df, \"Region\", \"Industry\", \"Records\", regions, industries)),\n",
    "                  (\"map\", lambda : generate_map(df, list(regions.values()))),\n",
    "                  (\"clean\", lambda : clean(df, \"../data/census2011_refined.csv\")),]\n",
    "\n",
    "results = timer(test_functions, 2)\n",
    "\n",
    "is_satisfactory(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Results</u>\n",
    "\n",
    "Most functions take between ~0.15 to ~0.3 seconds to execute, however, generate_plot() takes a substantially longer time to execute at ~1.8 seconds. More concerning, however, is the clean() function which takes ~30 seconds to execute, which is at least 100 times longer than the execution times of most other functions.\n",
    "\n",
    "The reason for why generate_plot() takes about 10 times longer to execute than other functions is likely because the values of the 3 axes have to be mapped such that the value -9 is changed to 0, this is because tick distances are automatically set by matplotlib, which is fine for numeric values, but these numeric values are displayed as meaningful text, therefore -9 is set to 0 so that all the ticks are equally spaced. The census data does not use the value 0, but admittedly this does make the code less re-usable, particularly for datasets that make use of both -9 and 0.\n",
    "\n",
    "There should be profiling done to see why generate_plot() takes so long to execute. The next cell will use cProfile to see exactly where time is lost when executing clean(). Originally, this section was supposed to use the profile module, however that is incompatible with the clean() function for some unknown reason.\n",
    "\n",
    "Refer to this page: https://docs.python.org/3/library/profile.html for an overview of what the column outputs mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_functions = [(\"clean\", \"clean(df, '../data/census2011_refined.csv')\")]\n",
    "\n",
    "run_profile(profile_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the use of a profiling tool, the time taken to execute the clean() function is ~50-60 seconds, ~20-30 seconds longer than running it using the timer() function in the previous block, this is likely due to overheads introduced by cProfile.\n",
    "\n",
    "To summarise the time spent:\n",
    "- ~57 seconds in total,\n",
    "- ~40 seconds for regex_match(), which is called several times by:\n",
    "- ensure_format(), taking ~50 seconds.\n",
    "This would leave ~7 seconds for other function calls, which is still a significant amount of time in comparison to the other functions tested with the timer(), however this also includes the execution of the other ensure_ functions as well as overheads introduced by cProfile.\n",
    "\n",
    "In regards to the large amount of time taken by ensure_format(), regex_match() takes up a signficant amount of time in total to be called, but mapping the results of regex_match() onto each column takes ~8 seconds, as seen in the profile where base.py:1078(_map_values) is called 18 times (same amount of columns in the dataframe) and takes ~48 seconds in total.\n",
    "\n",
    "To prove that this is the case, the cell below runs almost exactly the same function as clean(), but without calling the ensure_format() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = timer([(\"clean_no_format_check\", lambda : clean_no_format_check(df, \"../data/partial_refinement.csv\"))],2)\n",
    "\n",
    "is_satisfactory(new_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without calling the ensure_format() function, the clean-up function takes less than ~1 second to execute, which shows that ensure_format() is the main culprit in the slow down.\n",
    "\n",
    "#### Performance Recommendations\n",
    "The most significant amount of time saved is possible by replacing the regex matching with another way to validate the values of each cell. Since the majority of columns should contain numeric values, one possibly more efficient way of validating the data would be to compare the values directly to see if they are within the range of numbers stated in the variables pdf, instead of converting the value to a string and then matching the regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### Summary\n",
    "\n",
    "We have completed the following requirements to at least some extent:\n",
    "- Descriptive Analysis.\n",
    "- ipywidgets.\n",
    "- Analysising other data sets (migrationScotland.ipynb).\n",
    "- Analyse the performance of different steps of the analysis.\n",
    "- Quality Control and Data Refinement.\n",
    "- Using pandas for queries.\n",
    "- 3D Plots.\n",
    "- The 2D plots required by the specification.\n",
    "- Instructions on how to setup virtual environments.\n",
    "- Map to display data.\n",
    "- Use of groupby.\n",
    "\n",
    "#### Problems encountered\n",
    "For 3D plots, we were originally going to create a 3D bar plot, however due to matplotlib not accepting non-numeric values for that particular type of plot, several 2D bar plots were placed on the 3rd axis to create a 3D plot.\n",
    "\n",
    "We have had some difficulties with virtual environments, and whilst the instructions contained within the README.txt file should allow it to work, we cannot guarantee that it will work on all machines since all 3 team members have had different experiences with this.\n",
    "\n",
    "Due to time restraints we were unable to optimise the performance of the code based on the recommendations given under the <b>Analysing Performance</b> section of this report. We have also only made one map.\n",
    "\n",
    "#### Reproducibility and Reusability\n",
    "We believe our code should be reusable to some extent in other settings as most of our code is stored within separate files and this notebook accesses these files and and utilises the generic functions such as print_bars and print_pie.\n",
    "\n",
    "We also believe our code is reproducible for cases such as the next UK census, since a lot of our code is also designed towards these structures, such as the dictionaries in variables.py.\n",
    "\n",
    "#### Provenance\n",
    "\n",
    "We started our code using the provided census2011.ipynb Jupyter Notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "684b1123683431d89d3bfe9a89cc763215f4b8cd94b4aba1fb40ad45ff7c8b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
